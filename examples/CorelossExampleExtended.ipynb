{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9d6fc7-af39-42ca-8e85-a83957bf0946",
   "metadata": {},
   "source": [
    "# Coreloss Example Extended\n",
    "In this notebook, a typical workflow of EELS processing is shown on simulated data. This notebook shows one example of how core-loss quantification could be performed. This notebook is very similar to the *CorelossExample* notebook with the difference being in the simulation of the multispectrum which is explained in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9c69f6-af2d-4290-a305-9f6c197e7f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "#important for the em.MultiSpectrumVisualizer since this is an interactive plotting tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c057e443-1c9a-4a6f-8d76-07403ec6a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyEELSMODEL.api as em"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c7b16-a202-49f2-bc0c-d910185964b6",
   "metadata": {},
   "source": [
    "## Simulation core-loss\n",
    "In this section , the core-loss signal will be simulated. This step is in general not needed since we get the experimental data instead of simulating it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726cf8f3-c284-4bcb-9230-9c337ea9364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to make easy mask to make elemental maps\n",
    "def make_circular_mask(xco, yco, Rin, Rout, shape):\n",
    "    XX, YY = np.meshgrid(np.arange(shape[1])-yco, np.arange(shape[0])-xco)\n",
    "    R = np.sqrt(XX**2+YY**2)\n",
    "    \n",
    "    mask = np.zeros(shape)\n",
    "    boolean = (R>=Rin) & (R<Rout)\n",
    "    mask[boolean] = 1\n",
    "    return mask\n",
    "\n",
    "def make_rectangular_mask(xco, yco, width,height, shape):\n",
    "    mask = np.zeros(shape)\n",
    "    mask[xco:xco+width, yco:yco+height] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68a0bdd-e2f8-45d7-ac19-f1d43696e695",
   "metadata": {},
   "source": [
    "#### Elemental abundance maps\n",
    "Define the elements and the eges used. Add the atomic numbers since they will be used to have some estimate on the free mean path. \\\n",
    "Different masks are defined to showcase an elemental abundance at each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8e94ae-a79a-4046-84c7-7016daec97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = ['C', 'N', 'O', 'Fe']\n",
    "edges = ['K', 'K', 'K', 'L']\n",
    "Zs = [6, 7, 8, 26] #atomic weights\n",
    "\n",
    "#scan size elemental map\n",
    "xsize = 128\n",
    "ysize = 128\n",
    "maps = np.zeros((len(elements),xsize,ysize))\n",
    "\n",
    "#masks which define different regions. \n",
    "mask0 =make_rectangular_mask(5, 5, 20, 20, (xsize,ysize))\n",
    "mask1 =  make_rectangular_mask(90, 90, 20, 30, (xsize,ysize))\n",
    "mask2 = make_circular_mask(xsize//2, ysize//2, 20, 30, (xsize,ysize))\n",
    "mask3 = make_circular_mask(xsize//2, ysize//2, 0, 20, (xsize,ysize))\n",
    "\n",
    "#attribute different elemental values for different masks\n",
    "maps[0] = 1  #carbon elemental map\n",
    "maps[1] = 2*mask0 + mask1 #nitrogen elemental map\n",
    "maps[2] = mask2 #oxygen elemental map\n",
    "maps[3] = mask3+0.5*mask2 #iron elemental map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d20fd4-7b0c-4b5a-ae99-2f73cbc1d4b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#shows the real truth elemental abundance\n",
    "fig, ax = plt.subplots(1,len(elements))\n",
    "for ii in range(maps.shape[0]):\n",
    "    ax[ii].imshow(maps[ii], cmap='gray')\n",
    "    ax[ii].set_title(elements[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad57b31-85c4-4cff-b1c1-c1a487eb3a45",
   "metadata": {},
   "source": [
    "#### t/&lambda;\n",
    "Calculate some measure of inelastic mean free path to include this into the simulated data. Since a change in inelastic mean free path modfies the multiple scattering which then changes the shape of background and core loss edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eade1a02-2a12-4e01-a1f3-09624b234722",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = np.zeros((xsize, ysize))\n",
    "tlambda_map = np.zeros_like(adf)\n",
    "for ii in range(maps.shape[0]):\n",
    "    adf += (Zs[ii]*maps[ii])**2\n",
    "    tlambda_map += Zs[ii]*maps[ii]\n",
    "    \n",
    "tlambda_map = tlambda_map/tlambda_map.max() #maximum t/lambda is 1 for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730929e9-81c5-4773-9625-95844eb245cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'mean free path')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shows adf and mean-free path figure\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(adf, cmap='gray')\n",
    "ax[0].set_title(r'ADF like contrast')\n",
    "ax[1].imshow(tlambda_map, cmap='gray')\n",
    "ax[1].set_title('mean free path')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8324b46-c0d5-40ee-8fd6-f2383918ac42",
   "metadata": {},
   "source": [
    "#### Simulation part\n",
    "CoreLossSimulator is an object which simulates a core loss multispectrum from the given elements, maps, t/&lambda; and the settings.\\\n",
    "Here is a small description on how the multispectrum gets simulated:\n",
    "1. Calculate a low loss which contains a zero-loss (Gaussian) with a FWHM (1eV) and the low loss. The low loss only uses the bulk plasmons, these are calculated using the plasmon energy (22 eV) and t/&lambda;. In this simulation the only variying parameter in the low loss is the t/&lambda; . This is done to showcase the influence of multiple scattering on the core-loss spectra.\n",
    "2. The background is calculated by starting with a powerlaw (A E<sup>-3</sup>) which gets convolved with the low loss at each probe position.\n",
    "3. The core loss edges are calculated using the E0, alpha, beta and GOS tables available. The calculated shape then gets convolved with the low loss to thake the multiple scattering into account. The GOS tables used are the one calculated by [Zhang Zezhong](https://zenodo.org/records/7729585)\n",
    "4. Poisson noise is added to the core-loss.\n",
    "5. To emulate the effect of instabilities in the spectrometer, both the low loss and core loss are shifted at each probe position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29068205-96af-474b-9f0c-1fc98eeccb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "E0 = 300e3 #acceleration voltage [V]\n",
    "alpha = 1e-9 #convergence angle [rad]\n",
    "beta = 20e-3 #collection angle [rad]\n",
    "\n",
    "dispersion = 0.5 #[eV]\n",
    "offset = 200 #[eV]\n",
    "size = 2048 #number of pixel used in simulation [eV]\n",
    "\n",
    "settings = (E0, alpha, beta)\n",
    "msh = em.MultiSpectrumshape(dispersion, offset, size, xsize, ysize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "181bbd08-faf4-4d88-b996-d5a685806239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16384it [00:12, 1278.41it/s]\n",
      "16384it [00:37, 431.62it/s]\n",
      "16384it [00:00, 34154.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multispectrum is simulated\n"
     ]
    }
   ],
   "source": [
    "sim = em.CoreLossSimulator(msh, elements, edges, maps, tlambda_map, settings)\n",
    "sim.use_shift = True #add shift which experimentally arises due to instabilities\n",
    "sim.simulate_multispectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57d6ae0-95a2-4830-9340-15ab37156a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefine the multispectra for easy use\n",
    "hl = sim.multispectrum\n",
    "ll = sim.ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cdfa54-76d4-4088-a169-574f3a72028f",
   "metadata": {},
   "source": [
    "## Quantification Part\n",
    "The previous part is the more irrelevant part which simulates the core-loss. In most of the cases, the data is available and needs to be processed. In this part, a typical workflow on getting the elemental abundance together with estimated errors is shown. Note that the ElementalQuantification class has such a workflow implemented in it but here we show how one can design their own workflow to optimize the data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396852c-a1be-48ef-8269-063e1495b392",
   "metadata": {},
   "source": [
    "#### Visualization\n",
    "The first part of processing (EELS) data is by visually inspecting it. Here are some function which are available to visualize the data and do some manual inspection of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9568c6d9-6e90-482e-b60e-7f19521f5ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show the mean core loss spectrum\n",
    "hl.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eb6b5d7-70b5-4ca3-8695-9f962a2e50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show a single spectrum at index position nx, ny\n",
    "nx = 64\n",
    "ny = 64\n",
    "\n",
    "hl.setcurrentspectrum((64,64))\n",
    "hl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ae3ba4e-6cce-4ddc-a189-bf4a4900f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the mean low loss spectrum\n",
    "#note that the drift broadens the zero loss peak\n",
    "ll.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43a61786-af0b-484a-b3c8-847604cddb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyEELSMODEL.operators.multispectrumvisualizer.MultiSpectrumVisualizer at 0x26d18d552a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the multispectrum\n",
    "#use + to increase box size --> take average inside box\n",
    "#use - to descrease box size --> takes average inside box\n",
    "#arrows can be used to navigate \n",
    "#clicking and dragging also work to navigate\n",
    "\n",
    "em.MultiSpectrumVisualizer([hl])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475323f7-969f-4e73-9ae7-9e2c31292b17",
   "metadata": {},
   "source": [
    "#### Aligning multispectra\n",
    "The core-loss gets aligned using the low-loss. Multiple methods are available for find the appropriate shifts and correct for it.\n",
    "1. FastAlignZeroLoss: Uses the energy at which the maximum intensity is measured. The found shifts are applied by rolling each spectra to make it align. This method is fast and does not modify the inputted data via interpolation. Hence it cannot find subpixel positions. This method works best when the zero-loss peak is sharp and has a high intensity which is valid in most cases. In our experience, this method works really well for elemental quantification.\n",
    "2. AlignZeroLoss: Fits a model to the zero-loss peak where the model is a Gaussian or Lorentzian function which needs to be specified by the user. This method is a lot slower and can be unstable due to its non-linear fitting procedure but has the potential to correct for subpixel shifts and works for a noisy and not sharp zero-loss peak.\n",
    "3. AlignCrossCorrelation: Finds the shift which gives the best similarity between two spectra by cross correlation the two spectra. Subpixel accuracy can be obtained via interpolating the experimental data and finding the shift. This method is generally faster than the AlignZeroLoss but could fail if the low loss spectra are not very similar to each other. This method can also be used to align core-loss signal when no low-loss is available. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f16e0fb-8b8f-4558-9557-61b881d7d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_align = em.FastAlignZeroLoss(ll, other_spectra=[hl], cropping=True)\n",
    "align = em.AlignZeroLoss(ll, other_spectra=[hl], cropping=True)\n",
    "cros_align = em.AlignCrossCorrelation(ll, other_spectra=[hl], cropping=True, is_zlp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fa570a8-0233-4ce2-89ac-1205e7f86cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start using FastAlignZeroLoss object\n",
      "Start using AlignZeroLoss object\n",
      "Estimates the parameters for the fitting procedure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16384it [00:45, 357.26it/s]\n",
      "16384it [00:03, 4125.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start using AlignCrossCorrelation object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16384it [00:08, 2034.76it/s]\n",
      "16384it [00:03, 4327.35it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Start using FastAlignZeroLoss object')\n",
    "fast_align.perform_alignment()\n",
    "print('Start using AlignZeroLoss object')\n",
    "align.perform_alignment()\n",
    "print('Start using AlignCrossCorrelation object')\n",
    "cros_align.perform_alignment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c80b972c-31b7-4993-89f7-d12e2c913d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = fast_align.show_shift()\n",
    "fig = align.show_shift()\n",
    "fig = cros_align.show_shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dda863e-b09c-49f0-866a-895a6debb62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Core loss')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#small comparison plot between the different alignement methods. \n",
    "#there should be almost no difference between them\n",
    "#shows how to manipulate the data and visualize it via matplotlib \n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(fast_align.aligned.energy_axis, fast_align.aligned.mean().data, label='FastAlignZeroLoss') \n",
    "ax[0].plot(align.aligned.energy_axis, align.aligned.mean().data, label='AlignZeroLoss') \n",
    "ax[0].plot(fast_align.aligned.energy_axis, fast_align.aligned.mean().data, label='AlignCrossCorrelation') \n",
    "ax[0].set_title(r'Low loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(fast_align.aligned_others[0].energy_axis, fast_align.aligned_others[0].mean().data, label='FastAlignZeroLoss') \n",
    "ax[1].plot(align.aligned_others[0].energy_axis, align.aligned_others[0].mean().data, label='AlignZeroLoss') \n",
    "ax[1].plot(fast_align.aligned_others[0].energy_axis, fast_align.aligned_others[0].mean().data, label='AlignCrossCorrelation') \n",
    "ax[1].set_title(r'Core loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5729c2a-130e-4308-889c-10a4caf15905",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_al = fast_align.aligned_others[0] #coreloss which is used for quantification\n",
    "ll_al = fast_align.aligned #lowloss which is used for quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48f4d46-28e2-4b3f-b019-8139349ab858",
   "metadata": {},
   "source": [
    "#### Define the model\n",
    "The next step is to chose a proper model for the experimental data. In pyEELMODEL each model consist out of  components and each component has multiple parameters. For instance, a gaussian component has three parameters: ampltide, center and fwhm. For each parameter one can identify if it needs to be changeable or not. If it is not changeable then it will not be updated via the fitting procedure. The cross sections have multiple parameters but for elemental quantification only the amplitude is the unkown. More information on the model-based approach can be found here [[1]](https://doi.org/10.1016/j.ultramic.2006.05.006) \\\n",
    "The model for this example consists in this case out of three parts:\n",
    "1. **The background**: Historically a powerlaw was used to model the background but in this example a linear background model is used[[2]](https://doi.org/10.1016/j.ultramic.2023.113830). This keeps the entire model linear which is advantages because no starting parameters are needed and no iterations need to be performed to find the global optimum.\n",
    "2. **Atomic cross sections**: The generalized oscillator strengths from Zhang et al. [[3]](https://zenodo.org/records/7729585) are used. To properly calculate these cross sections, the acceleration voltage (E0), convergence angle (alpha) and collection angle (beta) are needed as input.\n",
    "3. **The low loss**: Due to multiple scattering, the shape of cross sections will be modified and this can be taken into account if the low loss is acquired from the same area. Note that the background will not be convoluted in the model since this is hard to incorporate due to the artifacts arising from the boundaries [[1]](https://doi.org/10.1016/j.ultramic.2006.05.006).\\\n",
    "\\\n",
    "[1] Verbeeck J. et al; Model based quantification of EELS spectra; Ultramicroscopy; 2004; doi:[10.1016/j.ultramic.2006.05.006](https://doi.org/10.1016/j.ultramic.2006.05.006)\\\n",
    "[2] Van den Broek W. et al; Convexity constrains on linear background models for electron energy loss spectra; Ultramicroscopy; 2023; doi:[10.1016/j.ultramic.2023.113830](https://doi.org/10.1016/j.ultramic.2023.113830)\\\n",
    "[3] Zhang Z. et al; Generalised oscillator strngth for core-shell excitation by fast electron based on Dirac solutions; Zenodo; 2023; doi:[10.5281/zenodo.7729585](https://zenodo.org/records/7729585)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f30802e-6459-413d-bbba-ffe14fea6a8f",
   "metadata": {},
   "source": [
    "##### Background component\n",
    "The linear combination of fixed powerlaws where the powers are given by rlist:\\\n",
    "$$bg(E) = \\sum_{i=0}^n A_i E^{-i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5eea7d5a-de95-486e-9ea5-dcb6874df70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyEELSMODEL.components.linear_background import LinearBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f554ec0c-830d-4444-b1e3-d6476c553d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "bg = LinearBG(specshape=hl_al.get_spectrumshape(), rlist=np.linspace(1,5,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd626e3-198a-497f-add0-3249b00a0a0e",
   "metadata": {},
   "source": [
    "##### Cross sections\n",
    "The cross sections are calculated using the cross sections of [Zezhong Zhang](https://zenodo.org/records/7729585). In pyEELSMODEL, the hydrogenic K and L edges and the cross section from [Segger, Guzzinati and Kohl](https://zenodo.org/records/7645765) are also available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a01805e5-1a89-45fe-b0dc-797d28b1af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyEELSMODEL.components.CLedge.zezhong_coreloss_edgecombined import ZezhongCoreLossEdgeCombined\n",
    "from pyEELSMODEL.components.CLedge.kohl_coreloss_edgecombined import KohlLossEdgeCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06770cf4-19bc-4773-be9c-0054511199be",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = ['C', 'N', 'O', 'Fe']\n",
    "edges = ['K', 'K', 'K', 'L']\n",
    "E0 = 300e3 \n",
    "alpha = 1e-9\n",
    "beta = 20e-3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d1146-d7d0-420d-9e43-6f77609f30ab",
   "metadata": {},
   "source": [
    "Showcase the difference between the two different GOS tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ed77fbc-6daf-45c2-b221-820db5f3f014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 is used\n",
      "L1 is used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26d319d1d20>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can take a bit of time since the cross section is calculated from the tabulated GOS arrays\n",
    "fig, ax = plt.subplots(1,len(elements))\n",
    "for ii in range(len(elements)):\n",
    "    compz = ZezhongCoreLossEdgeCombined(hl_al.get_spectrumshape(), 1, E0, alpha,beta, elements[ii], edges[ii])\n",
    "    compz.calculate() #calculates the cross section with given parameters\n",
    "    compk = KohlLossEdgeCombined(hl_al.get_spectrumshape(), 1, E0, alpha,beta, elements[ii], edges[ii]) \n",
    "    compk.calculate()\n",
    "\n",
    "    ax[ii].plot(compz.energy_axis, compz.data, label='Zhang')\n",
    "    ax[ii].plot(compk.energy_axis, compk.data, label='Kohl')\n",
    "ax[0].legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "537928c3-e23f-4a39-a600-21a6e3097ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 is used\n",
      "L1 is used\n"
     ]
    }
   ],
   "source": [
    "#can take a bit of time since the cross section is calculated from the tabulated GOS arrays\n",
    "#can chose which cross section you use \n",
    "comp_elements = []\n",
    "A = 1 #amplitude for cross section, since model is linear this value is not super important. For non-linear fitters the starting value could be important\n",
    "for elem, edge in zip(elements, edges):\n",
    "    #comp = ZezhongCoreLossEdgeCombined(hl_al.get_spectrumshape(), 1, E0, alpha,beta, elem, edge)\n",
    "    comp = KohlLossEdgeCombined(hl_al.get_spectrumshape(), 1, E0, alpha,beta, elem, edge)\n",
    "    comp_elements.append(comp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c780b6-241b-40b7-98ef-edf95d4ad7fd",
   "metadata": {},
   "source": [
    "##### Multiple scattering\n",
    "The calculated components are convolved with the low loss if indicated. For instance, the background component will not be convolved with the lowloss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7104c1ed-5071-4cc2-9743-6ddf333b5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyEELSMODEL.components.MScatter.mscatterfft import MscatterFFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7e064bc-398a-418d-abab-36cf6b146b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "llcomp  = MscatterFFT(hl_al.get_spectrumshape(), ll_al)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f70dec-446c-4f48-b73b-9c828b9a05f7",
   "metadata": {},
   "source": [
    "##### Model\n",
    "The model gets created by adding all the different components together into a list. It uses this information to calculate the resulting model and can be used as input for the fitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9bbe4b1-44e6-45cd-8395-efcadc268027",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = [bg]+comp_elements+[llcomp]\n",
    "mod = em.Model(hl_al.get_spectrumshape(), components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b86cb936-c134-47a9-a61c-bba8d2bc35e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "#shows the model with the given paramter values. \n",
    "mod.calculate()\n",
    "mod.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca7c0a5-2e93-4133-b5b3-77b8ef96ff2c",
   "metadata": {},
   "source": [
    "#### Finding optimal parameters for model\n",
    "Since the model we defined is linear, we can use a weighted linear fitter. The weights are determined from the assumption that the noise is poisson distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa1180c0-ba37-4914-988a-1e5ba9b591a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cannot use analytical gradients since a convolutor is inside model\n"
     ]
    }
   ],
   "source": [
    "#creates a fit object \n",
    "fit = em.LinearFitter(hl_al, mod, use_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02ff9f63-799d-4165-bd3b-75b91ffec165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16384it [00:38, 421.78it/s]\n"
     ]
    }
   ],
   "source": [
    "fit.multi_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec957ff7-11c6-473b-b16e-b9d94588809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 8)\n",
      "8 parameters are optimized in the fitting procedure\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'N K edge: 402 eV')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the fitted parameters can be found in .coeff_matrix attribute.\n",
    "print(fit.coeff_matrix.shape)\n",
    "print(str(fit.coeff_matrix.shape[2])+' parameters are optimized in the fitting procedure')\n",
    "\n",
    "#To know which parameter corresponds to which index in the coeff_matrix, following function can be used\n",
    "N_index = fit.get_param_index(comp_elements[1].parameters[0]) #comp_elements[1].parameters[0]: amplitude of nitrogen edge\n",
    "N_map = fit.coeff_matrix[:,:,N_index]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(N_map)\n",
    "ax.set_title(comp_elements[1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b22a467c-baba-4916-bc8e-2830b8b426b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function shows the elemental maps \n",
    "fig, maps, names = fit.show_map_result(comp_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffd5822a-2d62-4d8b-ab13-48a8de73cbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16384it [00:11, 1378.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#calculates the fitted model, this can be used to validate visually the fitted results\n",
    "multimodel = fit.model_to_multispectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ede6cc43-6a12-4b41-ac4f-133f25c6128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyEELSMODEL.operators.multispectrumvisualizer.MultiSpectrumVisualizer at 0x26d314c4c70>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em.MultiSpectrumVisualizer([hl_al, multimodel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a7277a6-f30f-4ab1-9dea-8d7e0e1fe6c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16384it [00:26, 611.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#calculates the cramer rao lower bound for the given paramter at each probe position\n",
    "crlb_Fe = fit.CRLB_map(comp_elements[3].parameters[0]) #comp_elements[3].parameters[0]: amplitude of iron edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "985c54c0-2e71-48b3-89d5-37f462303709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26d177f1ab0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(crlb_Fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348463f-e5c0-4d61-9ec6-816e9c3a74de",
   "metadata": {},
   "source": [
    "### ElementalQuantification class\n",
    "The last part shows how the ElementalQuantification class is used as workflow to get the same result. The workflow used in this example is similar to what is used in the ElementalQuantification class but this class gives some other attributes with which you can vary the workflow. For more information see the documentation or the other notebook ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc289a1d-8178-49db-bce6-25d9d1277532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cannot use analytical gradients since a convolutor is inside model\n",
      "16384it [00:37, 442.52it/s]\n",
      "16384it [00:12, 1320.05it/s]\n"
     ]
    }
   ],
   "source": [
    "quant = em.ElementalQuantification(hl, elements, edges, settings, ll=ll)\n",
    "quant.n_bgterms = 4\n",
    "quant.linear_fitter_method = 'ols'\n",
    "quant.do_procedure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59ec8335-3942-49f8-ae50-79bd4bf55de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant.show_elements_maps()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
